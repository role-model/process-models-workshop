# ML model selection with MESS simulations

## Key questions

1. How do I perform a inference using MESS simulations in R?

## Lesson objectives

After this lesson, learners should be able to...

1. Use RoLE simulations and RandomForest ML (w/ tidymodels) to perform inference
1. Interpret results in terms of story
1. Brainstorm applications to real data

## Planned exercises


* Lecture: How does ML work with MESS simulations?
* Run MESS model simulations
* ML assembly model classification
* ML parameter estimation
* Posterior predictive simulations (if time)
* Free time to experiment with other example datasets

### Lecture: How does ML work with MESS simulations?
Lecture: [How does machine learning work with MESS simulations?](https://docs.google.com/presentation/d/12fVO8Jzxvdm5nxcvITtpn3re8VJm4j1J96Y3zmBh6ZY/edit?usp=sharing)

#### Download the pre-baked simulations
Since it can take quite some time to run a number of simulations sufficient for
model selection and parameter estimation we will use a suite of pre-baked
simulations generated ahead of time. Go to the terminal tab in Rstudio and fetch
them with `wget` from the workshop site:
```
\# FIXME
# Make sure you're in the role-workshop directory
cd ~/role-workshop
wget https://compphylo.github.io/Oslo2019/MESS_files/MESS_simulations/SIMOUT.txt
wc -l SIMOUT.txt
```
    100%[======================================>] 14,234,338  50.0M/s   in 0.3s
    2019-08-11 01:25:27 (50.0 MB/s) - "SIMOUT.txt.1" saved [14234338/14234338]
    24440 SIMOUT.txt

:::{.callout-note}
The `wc` command counts the number of lines if you pass it the `-l` flag.
You can see this series of ~25k simulations is about 14MB.
:::

### ML assembly model classification
The first step is now to assess the model of community assembly that best
fits the data. The three models are `neutral`, in which all individuals are
ecologically equivalent; `competition`, in which species have traits, and
differential survival probability is weighted by distance of traits from
the trait mean in the local community (closer to the trait mean == higher
probability of death); and `filtering`, in which there is an environmental
optimum, and proximity of trait values to this optimum is positively
correlated with survival probability.

Basically we want to know, are individuals in the local community ecologically
equivalent, and if not are they interacting more with each other or more
with the local environment.

```R
install.packages("randomForest")
install.packages(pkgs = "caret", dependencies = c("Depends", "Imports"))
library(randomForest)
library(caret)
```

```R
simdata = MESS$load_local_sims("toysims-SIMOUT.csv")[[1]]

simdata$assembly_model <- as.factor(simdata$assembly_model)
table(simdata$assembly_model)
```
```default
competition     filtering   neutral
       1000          1000       999
```

#### Train the ML classifier
## 70/30 test/train split
tmp <- sample(2, nrow(simdata), replace = TRUE, prob = c(0.7, 0.3))
train <- simdata[tmp==1,]
test <- simdata[tmp==2,]

## Experiment with results for different axes of data!
rf <- randomForest(assembly_model ~ local_S + pi_h1 + abund_h1 + trait_h1, data=train, proximity=TRUE)
print(rf)

##
p1 <- predict(rf, train)
## confusionMatrix is in Caret, do we need it?
confusionMatrix(p1, train$assembly_model)

p2 <- predict(rf, test)
confusionMatrix(p2, test$assembly_model)

varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Variable Importance")

MDSplot(rf, train$assembly_model)

p_emp <- predict(rf, test[1, ], type="prob")
p_emp

#### Plot confusion matrix
#### Perform classification of empirical data and view results

### ML parameter estimation
Now that we have identified the neutral model as the most probable, we can
estimate parameters of the emipirical data given this model. Essentially,
we are asking the question "What are the parameters of the model that
generate summary statistics most similar to those of the empirical data?"

#### Train the ML regressor
#### Plot cross-validation results
#### Perform regression to predict dispersal_prob of empirical data and view results

## Key points
* Key
* point
* one
